# Ollama Workshop

Ein praktischer Einführungskurs zur Nutzung von Ollama für lokale Large Language Models (LLMs).

## Überblick

Dieser Workshop vermittelt die Grundlagen und fortgeschrittene Techniken zur Arbeit mit Ollama - einer Open-Source-Software zum lokalen Betrieb von LLMs. Die Teilnehmer lernen von der Installation bis zur eigenen Modellkonfiguration alle wichtigen Aspekte kennen.

## Inhalte

### [Kapitel 1: Ollama anfassen](course_materials/1_Kapitel.md)
Installation, erste Schritte und Modellkonfiguration mit dem Terminal

### [Kapitel 2: Ollama durch API betätigen](course_materials/2_Kapitel.md)
API-Zugriff und Integration mit externen Anwendungen (OpenRefine, Custom Apps)

### [Kapitel 3: Parameter von LLMs und Quantisierung](course_materials/3_Kapitel.md)
Verständnis von Modellparametern, Quantisierungsmethoden und Ressourcensteuerung

### [Kapitel 4: Unterschiedliche Modelle verwenden](course_materials/4_Kapitel.md)
Modelle von Huggingface nutzen und in Ollama einbinden

### [Kapitel 5: GGUF selber erstellen und verwenden](course_materials/5_Kapitel.md)
Eigene quantisierte Modelle mit llama.cpp erstellen

## Voraussetzungen

- Grundkenntnisse in der Arbeit mit dem Terminal
- Installiertes Ollama (siehe [ollama.com](https://ollama.com))

## Lizenz

Die Workshop-Materialien stehen unter der MIT-Lizenz.